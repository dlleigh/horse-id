#!/usr/bin/env python3
"""
Horse Name Normalization Pipeline Step

Reads from horse_photos_manifest.csv, normalizes horse names with CLI interaction,
outputs to horse_photos_manifest_normalized.csv

This script:
1. Loads the manifest from email ingestion
2. Attempts to normalize horse names against the master horse list
3. Prompts user for approval on uncertain matches
4. Saves approved mappings for consistency
5. Outputs normalized manifest for the next pipeline step
"""

import os
import yaml
import pandas as pd
import re
import difflib
import json
from datetime import datetime
from typing import List, Dict, Optional, Tuple

# --- Load Configuration ---
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

# --- Use the config values ---
DATA_ROOT = os.path.expanduser(config['paths']['data_root'])
INPUT_MANIFEST_FILE = config['paths']['manifest_file'].format(data_root=DATA_ROOT)
OUTPUT_MANIFEST_FILE = config['paths']['normalized_manifest_file'].format(data_root=DATA_ROOT)
HORSE_HERDS_FILE = config['paths']['horse_herds_file'].format(data_root=DATA_ROOT)
APPROVED_MAPPINGS_FILE = config['normalization']['approved_mappings_file'].format(data_root=DATA_ROOT)
AUTO_APPROVE_THRESHOLD = config['normalization']['auto_approve_threshold']


class NormalizationCandidate:
    """Represents a potential normalized name with confidence score."""
    def __init__(self, name: str, confidence: float, method: str):
        self.name = name
        self.confidence = confidence
        self.method = method


def load_master_horse_list() -> List[str]:
    """Load the master horse list from horse_herds CSV file (output of parse_horse_herds.py)."""
    if not os.path.exists(HORSE_HERDS_FILE):
        print(f"Warning: Horse herds file not found at {HORSE_HERDS_FILE}")
        print("Please run 'python parse_horse_herds.py' first to generate the horse herds CSV.")
        return []
    
    try:
        # Read CSV file generated by parse_horse_herds.py
        df = pd.read_csv(HORSE_HERDS_FILE)
        
        # Use the basename column for normalization matching
        if 'basename' in df.columns:
            horse_names = df['basename'].dropna().unique().tolist()
        elif 'horse_name' in df.columns:
            # Fallback to horse_name if basename not available
            horse_names = df['horse_name'].dropna().unique().tolist()
        else:
            print(f"Error: Neither 'basename' nor 'horse_name' column found in {HORSE_HERDS_FILE}")
            return []
        
        print(f"Loaded {len(horse_names)} horses from horse herds file")
        return [str(name).strip() for name in horse_names if str(name).strip()]
    
    except Exception as e:
        print(f"Error loading horse herds file: {e}")
        return []


def normalize_name_for_comparison(name: str) -> str:
    """Normalize name for comparison (lowercase, remove special chars)."""
    if not name:
        return ""
    # Convert to lowercase and remove apostrophes, spaces, special chars
    normalized = re.sub(r"['\s\-_]", '', name.lower())
    return normalized


def create_base_name(name: str) -> str:
    """Create base name by removing trailing numbers."""
    # Remove trailing space + number pattern
    base = re.sub(r'\s+\d+$', '', name)
    return base.strip()


def find_exact_matches(original_name: str, master_list: List[str]) -> List[NormalizationCandidate]:
    """Find exact matches in master list."""
    candidates = []
    
    for master_name in master_list:
        # Skip None values
        if master_name is None:
            continue
            
        # Exact match
        if original_name == master_name:
            candidates.append(NormalizationCandidate(master_name, 1.0, "exact"))
            continue
        
        # Case-insensitive exact match
        if original_name.lower() == master_name.lower():
            candidates.append(NormalizationCandidate(master_name, 0.95, "exact_case_insensitive"))
            continue
    
    return candidates


def find_base_name_matches(original_name: str, master_list: List[str]) -> List[NormalizationCandidate]:
    """Find matches after removing trailing numbers."""
    candidates = []
    original_base = create_base_name(original_name)
    original_base_norm = normalize_name_for_comparison(original_base)
    
    for master_name in master_list:
        # Skip None values
        if master_name is None:
            continue
            
        master_base = create_base_name(master_name)
        master_base_norm = normalize_name_for_comparison(master_base)
        
        # Match if base names are the same (this handles both directions)
        # e.g., "Cowboy" matches "Cowboy 1" AND "Cowboy 1" matches "Cowboy"
        if original_base_norm == master_base_norm and original_base_norm:
            candidates.append(NormalizationCandidate(master_name, 0.9, "base_name"))
    
    return candidates


def find_special_case_matches(original_name: str, master_list: List[str]) -> List[NormalizationCandidate]:
    """Find matches for known special cases."""
    candidates = []
    
    # Define known variations
    special_cases = {
        'goodwill': 'Good Will',
        'good will': 'Good Will',
        'ohallon': "O'Halon",
        "o'halon": "O'Halon",
        'ohalon': "O'Halon",
        'davinci': 'DaVinci',
        'da vinci': 'DaVinci',
        'ceelo': 'Ceelo',
        'cee': 'Ceelo',
        'guinness': 'Guinness',
        'guiness': 'Guinness',
        'isaac': 'Isaac',
        'issac': 'Isaac',
        'raffiki': 'Raffiki',
        'rafikki': 'Raffiki',
        'conola': 'Canola',
        'canola': 'Canola',
    }
    
    original_norm = normalize_name_for_comparison(original_name)
    
    if original_norm in special_cases:
        target_name = special_cases[original_norm]
        # Check if target exists in master list
        for master_name in master_list:
            # Skip None values
            if master_name is None:
                continue
            if normalize_name_for_comparison(master_name) == normalize_name_for_comparison(target_name):
                candidates.append(NormalizationCandidate(master_name, 0.95, "special_case"))
                break
    
    return candidates


def find_fuzzy_matches(original_name: str, master_list: List[str], threshold: float = 0.85) -> List[NormalizationCandidate]:
    """Find fuzzy matches using sequence matching."""
    candidates = []
    original_norm = normalize_name_for_comparison(original_name)
    
    for master_name in master_list:
        # Skip None values
        if master_name is None:
            continue
            
        master_norm = normalize_name_for_comparison(master_name)
        
        if original_norm and master_norm:
            similarity = difflib.SequenceMatcher(None, original_norm, master_norm).ratio()
            
            if similarity >= threshold:
                candidates.append(NormalizationCandidate(master_name, similarity, "fuzzy"))
    
    # Sort by confidence descending
    candidates.sort(key=lambda x: x.confidence, reverse=True)
    return candidates[:5]  # Limit to top 5 fuzzy matches


def find_substring_matches(original_name: str, master_list: List[str]) -> List[NormalizationCandidate]:
    """Find substring matches where one name is contained in another."""
    candidates = []
    original_norm = normalize_name_for_comparison(original_name)
    
    for master_name in master_list:
        # Skip None values
        if master_name is None:
            continue
            
        master_norm = normalize_name_for_comparison(master_name)
        
        if original_norm and master_norm:
            # Check if names are similar length (within 3 characters) and both are reasonable length
            if abs(len(original_name) - len(master_name)) <= 3 and min(len(original_name), len(master_name)) >= 3:
                if original_norm in master_norm or master_norm in original_norm:
                    candidates.append(NormalizationCandidate(master_name, 0.8, "substring"))
    
    return candidates


def find_approved_name_matches(original_name: str, approved_names: List[str]) -> List[NormalizationCandidate]:
    """Find matches against previously approved normalized names."""
    candidates = []
    
    if not approved_names:
        return candidates
    
    # Use the same matching strategies as the master list, but with different method names
    # and slightly lower confidence since these are user-approved rather than official
    
    # 1. Exact matches
    for approved_name in approved_names:
        if approved_name is None:
            continue
            
        # Exact match
        if original_name == approved_name:
            candidates.append(NormalizationCandidate(approved_name, 0.95, "approved_exact"))
            continue
        
        # Case-insensitive exact match  
        if original_name.lower() == approved_name.lower():
            candidates.append(NormalizationCandidate(approved_name, 0.90, "approved_exact_case_insensitive"))
            continue
    
    # 2. Base name matches (e.g., "Sock" -> "Socks")
    original_base = create_base_name(original_name)
    original_base_norm = normalize_name_for_comparison(original_base)
    
    for approved_name in approved_names:
        if approved_name is None:
            continue
            
        approved_base = create_base_name(approved_name)
        approved_base_norm = normalize_name_for_comparison(approved_base)
        
        if original_base_norm == approved_base_norm and original_base_norm:
            candidates.append(NormalizationCandidate(approved_name, 0.85, "approved_base_name"))
    
    # 3. Substring matches 
    original_norm = normalize_name_for_comparison(original_name)
    
    for approved_name in approved_names:
        if approved_name is None:
            continue
            
        approved_norm = normalize_name_for_comparison(approved_name)
        
        if original_norm and approved_norm:
            # For approved names, be more flexible with substring matching
            # Check if one name is contained in the other and both are reasonable length
            if min(len(original_name), len(approved_name)) >= 3:
                if original_norm in approved_norm or approved_norm in original_norm:
                    candidates.append(NormalizationCandidate(approved_name, 0.80, "approved_substring"))
    
    # 4. Fuzzy matches
    for approved_name in approved_names:
        if approved_name is None:
            continue
            
        approved_norm = normalize_name_for_comparison(approved_name)
        
        if original_norm and approved_norm:
            similarity = difflib.SequenceMatcher(None, original_norm, approved_norm).ratio()
            
            if similarity >= 0.80:  # Slightly lower threshold for approved names
                candidates.append(NormalizationCandidate(approved_name, similarity * 0.9, "approved_fuzzy"))
    
    # Remove duplicates and sort by confidence
    seen = set()
    unique_candidates = []
    for candidate in candidates:
        if candidate.name not in seen:
            seen.add(candidate.name)
            unique_candidates.append(candidate)
    
    unique_candidates.sort(key=lambda x: x.confidence, reverse=True)
    return unique_candidates[:3]  # Limit to top 3 approved name matches


def get_normalization_candidates(original_name: str, master_list: List[str], approved_mappings: Dict[str, str] = None) -> List[NormalizationCandidate]:
    """Get all possible normalization candidates for a name."""
    if not original_name or not original_name.strip():
        return []
    
    candidates = []
    
    # Try different matching strategies against master list
    candidates.extend(find_exact_matches(original_name, master_list))
    candidates.extend(find_special_case_matches(original_name, master_list))
    candidates.extend(find_base_name_matches(original_name, master_list))
    candidates.extend(find_substring_matches(original_name, master_list))
    candidates.extend(find_fuzzy_matches(original_name, master_list))
    
    # Also search against approved names if available
    if approved_mappings:
        approved_names = get_approved_names_list(approved_mappings)
        candidates.extend(find_approved_name_matches(original_name, approved_names))
    
    # Remove duplicates and sort by confidence
    seen = set()
    unique_candidates = []
    for candidate in candidates:
        if candidate.name not in seen:
            seen.add(candidate.name)
            unique_candidates.append(candidate)
    
    unique_candidates.sort(key=lambda x: x.confidence, reverse=True)
    return unique_candidates


def load_approved_mappings() -> Dict[str, str]:
    """Load previously approved name mappings."""
    if not os.path.exists(APPROVED_MAPPINGS_FILE):
        return {}
    
    try:
        with open(APPROVED_MAPPINGS_FILE, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"Warning: Could not load approved mappings: {e}")
        return {}


def get_approved_names_list(approved_mappings: Dict[str, str]) -> List[str]:
    """Extract unique normalized names from approved mappings for candidate searching."""
    if not approved_mappings:
        return []
    
    # Get all normalized names (values from the mappings)
    approved_names = set()
    for normalized_name in approved_mappings.values():
        if normalized_name and str(normalized_name).strip():
            approved_names.add(str(normalized_name).strip())
    
    return list(approved_names)


def save_approved_mapping(original_name: str, normalized_name: str, approved_mappings: Dict[str, str], master_list: List[str] = None):
    """Save an approved name mapping when needed for future reference."""
    should_save = False
    
    if original_name != normalized_name:
        # Always save actual normalizations
        should_save = True
    elif master_list is not None and original_name not in master_list:
        # Save identity mappings for names NOT in the master list
        # (user explicitly chose to keep a name that's not in the official list)
        should_save = True
    # Don't save identity mappings for names already in the master list
    
    if should_save:
        approved_mappings[original_name] = normalized_name
        
        try:
            # Ensure directory exists
            os.makedirs(os.path.dirname(APPROVED_MAPPINGS_FILE), exist_ok=True)
            
            with open(APPROVED_MAPPINGS_FILE, 'w') as f:
                json.dump(approved_mappings, f, indent=2)
        except Exception as e:
            print(f"Warning: Could not save approved mapping: {e}")


def prompt_user_decision(original_name: str, candidates: List[NormalizationCandidate]) -> str:
    """Prompt user to choose from normalization candidates."""
    print(f"\n" + "="*60)
    print(f"Horse name needs review: '{original_name}'")
    print("="*60)
    
    if not candidates:
        print("No suggested matches found.")
        print("Options:")
        print("  1. Keep original name")
        print("  2. Enter custom name")
        keep_option = 1
        custom_option = 2
    else:
        print("Suggested matches:")
        for i, candidate in enumerate(candidates, 1):
            print(f"  {i}. {candidate.name} (confidence: {candidate.confidence:.2f}, method: {candidate.method})")
        
        keep_option = len(candidates) + 1
        custom_option = len(candidates) + 2
        
        print(f"  {keep_option}. Keep original name")
        print(f"  {custom_option}. Enter custom name")
    
    max_option = custom_option
    
    while True:
        try:
            choice = input(f"Choose option (1-{max_option}): ").strip()
            choice_num = int(choice)
            
            if 1 <= choice_num <= len(candidates):
                return candidates[choice_num-1].name
            elif choice_num == keep_option:
                return original_name
            elif choice_num == custom_option:
                while True:
                    custom = input("Enter custom normalized name: ").strip()
                    if custom:
                        return custom
                    print("Please enter a non-empty name.")
            else:
                print(f"Invalid choice. Please enter a number between 1 and {max_option}.")
        except (ValueError, KeyboardInterrupt):
            if isinstance(sys.last_value, KeyboardInterrupt):
                print("\nOperation cancelled.")
                return original_name
            print("Invalid input. Please enter a number.")


def main():
    """Main normalization process."""
    print("Starting horse name normalization process...")
    print(f"Input manifest: {INPUT_MANIFEST_FILE}")
    print(f"Output manifest: {OUTPUT_MANIFEST_FILE}")
    
    # Load input manifest
    if not os.path.exists(INPUT_MANIFEST_FILE):
        print(f"Error: Input manifest not found at {INPUT_MANIFEST_FILE}")
        print("Please run 'python ingest_from_email.py' first.")
        return
    
    try:
        input_df = pd.read_csv(INPUT_MANIFEST_FILE, dtype={'message_id': str, 'filename': str})
        print(f"Loaded {len(input_df)} rows from input manifest")
    except Exception as e:
        print(f"Error reading input manifest: {e}")
        return
    
    # Load master horse list
    master_list = load_master_horse_list()
    if not master_list:
        print("Warning: No master horse list available. Normalization will be limited.")
    
    # Load previously approved mappings
    approved_mappings = load_approved_mappings()
    print(f"Loaded {len(approved_mappings)} previously approved mappings")
    
    # Create output dataframe
    output_df = input_df.copy()
    output_df['normalized_horse_name'] = ''
    output_df['normalization_confidence'] = 0.0
    output_df['normalization_method'] = ''
    output_df['normalization_timestamp'] = ''
    
    # Get unique horse names to process
    unique_names = input_df['horse_name'].dropna().unique()
    print(f"Found {len(unique_names)} unique horse names to process")
    
    # Process each unique horse name
    for i, original_name in enumerate(unique_names, 1):
        print(f"\nProcessing {i}/{len(unique_names)}: '{original_name}'")
        
        if original_name in approved_mappings:
            # Use previously approved mapping
            normalized_name = approved_mappings[original_name]
            confidence = 1.0
            method = "previously_approved"
            print(f"  Using previously approved mapping: '{original_name}' -> '{normalized_name}'")
        else:
            # Get normalization candidates
            candidates = get_normalization_candidates(original_name, master_list, approved_mappings)
            
            if candidates and candidates[0].confidence >= AUTO_APPROVE_THRESHOLD:
                # Auto-approve high confidence matches
                best_candidate = candidates[0]
                normalized_name = best_candidate.name
                confidence = best_candidate.confidence
                method = f"auto_{best_candidate.method}"
                print(f"  Auto-approved: '{original_name}' -> '{normalized_name}' (confidence: {confidence:.2f})")
                
                # Save this decision
                save_approved_mapping(original_name, normalized_name, approved_mappings, master_list)
            else:
                # Prompt user for decision
                normalized_name = prompt_user_decision(original_name, candidates)
                confidence = 1.0 if normalized_name == original_name else 0.9
                method = "user_approved"
                
                print(f"  User decision: '{original_name}' -> '{normalized_name}'")
                
                # Save this decision
                save_approved_mapping(original_name, normalized_name, approved_mappings, master_list)
        
        # Update all rows with this horse name
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        mask = output_df['horse_name'] == original_name
        
        output_df.loc[mask, 'normalized_horse_name'] = normalized_name
        output_df.loc[mask, 'normalization_confidence'] = confidence
        output_df.loc[mask, 'normalization_method'] = method
        output_df.loc[mask, 'normalization_timestamp'] = timestamp
    
    # Ensure output directory exists
    os.makedirs(os.path.dirname(OUTPUT_MANIFEST_FILE), exist_ok=True)
    
    # Save normalized manifest
    try:
        output_df.to_csv(OUTPUT_MANIFEST_FILE, index=False)
        print(f"\nNormalized manifest saved to: {OUTPUT_MANIFEST_FILE}")
        
        # Print summary
        total_rows = len(output_df)
        unique_original = len(output_df['horse_name'].unique())
        unique_normalized = len(output_df['normalized_horse_name'].unique())
        
        print(f"\nSummary:")
        print(f"  Total rows processed: {total_rows}")
        print(f"  Original unique names: {unique_original}")
        print(f"  Normalized unique names: {unique_normalized}")
        print(f"  Names consolidated: {unique_original - unique_normalized}")
        
        # Method breakdown
        method_counts = output_df['normalization_method'].value_counts()
        print(f"\nNormalization methods used:")
        for method, count in method_counts.items():
            print(f"  {method}: {count} rows")
        
    except Exception as e:
        print(f"Error saving output manifest: {e}")
        return
    
    print("\nHorse name normalization completed successfully!")
    print("Next step: Run 'python multi_horse_detector.py'")


if __name__ == '__main__':
    import sys
    main()